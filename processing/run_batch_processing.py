import os
import multiprocessing
import time
from pymilvus import utility

import config

# Bá» cÃ¡c import khÃ´ng cáº§n thiáº¿t á»Ÿ Ä‘Ã¢y, chÃºng sáº½ Ä‘Æ°á»£c xá»­ lÃ½ trong worker
from processing.worker import (
    process_single_media_file,
    init_worker,
)

# ÄÆ°á»ng dáº«n Ä‘áº¿n tá»‡p log, Ä‘áº·t cÃ¹ng cáº¥p vá»›i file script nÃ y
LOG_FILE_PATH = os.path.join(os.path.dirname(__file__), "processed_files.log")


def get_processed_files():
    """Äá»c danh sÃ¡ch cÃ¡c tá»‡p Ä‘Ã£ xá»­ lÃ½ tá»« tá»‡p log."""
    if not os.path.exists(LOG_FILE_PATH):
        return set()
    try:
        with open(LOG_FILE_PATH, "r") as f:
            # DÃ¹ng .strip() Ä‘á»ƒ loáº¡i bá» cÃ¡c khoáº£ng tráº¯ng hoáº·c dÃ²ng trá»‘ng
            return set(line.strip() for line in f if line.strip())
    except IOError as e:
        print(f"âš ï¸  Warning: Could not read log file {LOG_FILE_PATH}: {e}")
        return set()


def main():
    print("=" * 60)
    print("ğŸš€ STARTING NEW BATCH PROCESSING PIPELINE (Resumable) ğŸš€")
    print("=" * 60)

    # 1. Chá»‰ cáº§n setup DB má»™t láº§n tá»« main process
    print("--- STEP 1: Setting up Databases ---")
    try:
        from database.milvus_connector import MilvusConnector
        from database.es_connector import ElasticsearchConnector

        MilvusConnector().setup_visual_collection()
        ElasticsearchConnector().setup_transcript_index()
        print("âœ… Databases are ready.\n")
    except Exception as e:
        print(f"âŒ Critical error during DB setup: {e}")
        return

    # 2. QuÃ©t thÆ° má»¥c data vÃ  lá»c ra cÃ¡c tá»‡p chÆ°a xá»­ lÃ½
    print("--- STEP 2: Scanning for Media Files ---")
    processed_files = get_processed_files()
    if processed_files:
        print(f"Found {len(processed_files)} previously processed files to skip.")

    all_files_in_dir = [
        f
        for f in os.listdir(config.DATA_DIR)
        if f.lower().endswith(config.MEDIA_EXTENSIONS + config.IMAGE_EXTENSIONS)
    ]

    files_to_process_paths = [
        os.path.join(config.DATA_DIR, f)
        for f in all_files_in_dir
        if f not in processed_files  # Lá»c bá» cÃ¡c tá»‡p Ä‘Ã£ cÃ³ trong log
    ]

    if not files_to_process_paths:
        print("âœ… No new media files to process. Exiting.")
        return
    print(f"Found {len(files_to_process_paths)} new files to process.\n")

    # 3. Sá»­ dá»¥ng multiprocessing.Pool vá»›i initializer vÃ  Lock
    num_processes = config.PROCESSING_WORKERS
    print(f"--- STEP 3: Starting Parallel Processing with {num_processes} workers ---")
    start_time = time.time()

    # Táº¡o má»™t Lock Ä‘á»ƒ ghi file log an toÃ n tá»« nhiá»u process
    manager = multiprocessing.Manager()
    lock = manager.Lock()

    # Sá»­ dá»¥ng initializer Ä‘á»ƒ má»—i worker chá»‰ load model má»™t láº§n
    # vÃ  truyá»n Lock vÃ o cho má»—i worker process
    init_args = (lock, LOG_FILE_PATH)
    with multiprocessing.Pool(
        processes=num_processes, initializer=init_worker, initargs=init_args
    ) as pool:
        pool.map(process_single_media_file, files_to_process_paths)

    end_time = time.time()
    print("\n--- STEP 4: Finalizing ---")

    # Flush Milvus collection Ä‘á»ƒ Ä‘áº£m báº£o táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c ghi
    try:
        print("Flushing Milvus collection to ensure data persistence...")
        # (MilvusConnector Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ viá»‡c nÃ y má»™t cÃ¡ch an toÃ n)
        milvus_conn = MilvusConnector()
        collection = milvus_conn.get_collection()

        if collection:
            collection.flush()
            print("âœ… Milvus flush complete.")
        else:
            print("âš ï¸ Warning: Could not get Milvus collection to flush.")

    except Exception as e:
        # Giá»¯ láº¡i Ä‘á»ƒ báº¯t cÃ¡c lá»—i khÃ¡c cÃ³ thá»ƒ xáº£y ra
        print(f"âš ï¸ Warning: Could not flush Milvus collection: {e}")

    print("\n" + "=" * 60)
    print("ğŸ‰ğŸ‰ğŸ‰ ALL BATCH PROCESSING COMPLETE! ğŸ‰ğŸ‰ğŸ‰")
    print(f"Total processing time for this run: {end_time - start_time:.2f} seconds.")
    print("Your data is now indexed in Milvus and Elasticsearch.")
    print("=" * 60)
