import asyncio
import os
import base64
from typing import List, Dict, Optional
import numpy as np
import cv2
from elasticsearch import AsyncElasticsearch
from sentence_transformers import CrossEncoder

import config
from core.vision import VisionProcessor
from api.schemas import (
    VisualResult,
    AudioResult,
    MatchDetail,
    UnifiedResult,
)
from database.milvus_connector import MilvusConnector

# Kh·ªüi t·∫°o c√°c t√†i nguy√™n d√πng chung m·ªôt l·∫ßn khi service kh·ªüi ƒë·ªông
print("üöÄ Initializing Search Service...")
vision_processor = VisionProcessor(config.CLIP_MODEL_ID)
milvus_conn = MilvusConnector()
# ƒê·∫£m b·∫£o collection ƒë√£ ƒë∆∞·ª£c load
milvus_collection = milvus_conn.get_collection()
if milvus_collection is None:
    milvus_conn.setup_visual_collection()
    milvus_collection = milvus_conn.get_collection()

es_client = AsyncElasticsearch(f"http://{config.ES_HOST}:{config.ES_PORT}")

# T·∫£i model Cross-Encoder cho b∆∞·ªõc Re-ranking
print(f"Loading Re-ranker model: {config.CROSS_ENCODER_MODEL_ID}")
cross_encoder = CrossEncoder(config.CROSS_ENCODER_MODEL_ID, max_length=512)
print("‚úÖ Search Service is ready!")


class SearchService:
    """
    Ch·ª©a logic t√¨m ki·∫øm, giao ti·∫øp v·ªõi Milvus v√† Elasticsearch.
    C√°c h√†m t√¨m ki·∫øm ƒë∆∞·ª£c thi·∫øt k·∫ø b·∫•t ƒë·ªìng b·ªô ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng.
    """

    def __init__(self):
        # C√°c t√†i nguy√™n n·∫∑ng ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o b√™n ngo√†i class
        self.vision_processor = vision_processor
        self.milvus_collection = milvus_collection
        self.es_client = es_client
        self.cross_encoder = cross_encoder

    async def _perform_visual_search(self, text: str, top_k: int) -> List[VisualResult]:
        """Th·ª±c hi·ªán t√¨m ki·∫øm vector b·∫•t ƒë·ªìng b·ªô tr√™n Milvus."""
        print(f"üîç Performing async visual search for: '{text}' (top_k={top_k})")
        query_vector = self.vision_processor.text_to_embedding(text)

        search_params = {
            "metric_type": "IP",
            "params": {
                "nprobe": 16
            },  # Tinh ch·ªânh gi√° tr·ªã n√†y ƒë·ªÉ c√¢n b·∫±ng t·ªëc ƒë·ªô/ƒë·ªô ch√≠nh x√°c
        }

        # Milvus search l√† I/O-bound, c√≥ th·ªÉ ch·∫°y trong aio.to_thread
        # Ho·∫∑c ch·ªù pymilvus h·ªó tr·ª£ async-native
        def search_sync():
            return self.milvus_collection.search(
                data=[query_vector.flatten()],
                anns_field="vector",
                param=search_params,
                limit=top_k,
                output_fields=["media_id", "timestamp"],
            )

        results = await asyncio.to_thread(search_sync)

        visual_results = []
        for hit in results[0]:
            visual_results.append(
                VisualResult(
                    id=hit.entity.get("media_id"),
                    score=hit.distance,
                    timestamp=hit.entity.get("timestamp"),
                )
            )
        return visual_results

    async def _perform_audio_search(self, text: str, top_k: int) -> List[AudioResult]:
        """Th·ª±c hi·ªán t√¨m ki·∫øm text b·∫•t ƒë·ªìng b·ªô tr√™n Elasticsearch."""
        print(f"üó£Ô∏è Performing async audio search for: '{text}' (top_k={top_k})")
        query = {
            "match": {
                "text": {
                    "query": text,
                    "operator": "and",  # Y√™u c·∫ßu t·∫•t c·∫£ c√°c t·ª´ trong query ph·∫£i xu·∫•t hi·ªán
                }
            }
        }

        response = await self.es_client.search(
            index=config.TRANSCRIPT_INDEX_NAME, query=query, size=top_k
        )

        audio_results = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            audio_results.append(
                AudioResult(
                    id=source["media_id"],
                    score=hit["_score"],  # Elasticsearch score
                    match=source["text"],
                    start=source["start"],
                    end=source["end"],
                )
            )
        return audio_results

    async def perform_unified_search(
        self, text: str, top_k: int
    ) -> List[UnifiedResult]:
        """
        Th·ª±c hi·ªán t√¨m ki·∫øm h·ª£p nh·∫•t theo ki·∫øn tr√∫c Recall -> Fusion -> Re-rank.
        """
        print(f"üöÄ Performing unified search for: '{text}' (top_k={top_k})")
        K_FOR_RECALL = 100  # L·∫•y nhi·ªÅu ·ª©ng vi√™n h∆°n ·ªü b∆∞·ªõc recall

        # --- B∆Ø·ªöC 1: RECALL (B·∫•t ƒë·ªìng b·ªô) ---
        # T·∫°o c√°c task ƒë·ªÉ ch·∫°y song song
        visual_recall_task = self._perform_visual_search(text, K_FOR_RECALL)
        audio_recall_task = self._perform_audio_search(text, K_FOR_RECALL)

        # Ch·∫°y v√† ƒë·ª£i k·∫øt qu·∫£ t·ª´ c·∫£ hai ngu·ªìn
        visual_candidates, audio_candidates = await asyncio.gather(
            visual_recall_task, audio_recall_task
        )

        # --- B∆Ø·ªöC 2: FUSION ---
        # D√πng RRF ƒë·ªÉ k·∫øt h·ª£p k·∫øt qu·∫£
        fused_scores = self._fuse_results_rrf(visual_candidates, audio_candidates)
        fused_candidates = sorted(
            fused_scores.items(), key=lambda item: item[1]["score"], reverse=True
        )

        # --- B∆Ø·ªöC 3: RE-RANK ---
        # Ch·ªâ re-rank nh·ªØng ·ª©ng vi√™n c√≥ k·∫øt qu·∫£ audio match
        rerank_candidates = []
        non_rerank_candidates = []

        # T·∫°o map t·ª´ media_id -> text match ƒë·∫ßu ti√™n ƒë·ªÉ re-rank
        audio_match_map = {}
        for res in audio_candidates:
            if res.id not in audio_match_map:
                audio_match_map[res.id] = res.match

        for media_id, data in fused_candidates:
            if "audio" in data["reason"] and media_id in audio_match_map:
                rerank_candidates.append((media_id, data, audio_match_map[media_id]))
            else:
                non_rerank_candidates.append((media_id, data))

        if rerank_candidates:
            print(
                f"üß† Re-ranking {len(rerank_candidates)} candidates with CrossEncoder..."
            )
            # Chu·∫©n b·ªã c·∫∑p [query, text]
            pairs = [[text, candidate[2]] for candidate in rerank_candidates]

            # Ch·∫°y model (t√°c v·ª• n·∫∑ng, ch·∫°y trong thread)
            rerank_scores = await asyncio.to_thread(
                self.cross_encoder.predict, pairs, show_progress_bar=False
            )

            # C·∫≠p nh·∫≠t ƒëi·ªÉm s·ªë v·ªõi ƒëi·ªÉm t·ª´ Cross-Encoder
            for i, score in enumerate(rerank_scores):
                # K·∫øt h·ª£p ƒëi·ªÉm RRF v√† ƒëi·ªÉm Cross-Encoder
                rerank_candidates[i][1]["score"] += (
                    score * 2.0
                )  # TƒÉng tr·ªçng s·ªë cho re-ranker

        # Gh√©p l·∫°i danh s√°ch ·ª©ng vi√™n v√† s·∫Øp x·∫øp l·∫ßn cu·ªëi
        all_candidates = [
            (item[0], item[1]) for item in rerank_candidates
        ] + non_rerank_candidates
        sorted_media = sorted(
            all_candidates, key=lambda item: item[1]["score"], reverse=True
        )

        # --- B∆Ø·ªöC 4: T·ªîNG H·ª¢P K·∫æT QU·∫¢ ---
        all_details = {}
        # Thu th·∫≠p chi ti·∫øt t·ª´ visual
        for res in visual_candidates:
            if res.id not in all_details:
                all_details[res.id] = []
            all_details[res.id].append(
                MatchDetail(type="visual", timestamp=res.timestamp, score=res.score)
            )
        # Thu th·∫≠p chi ti·∫øt t·ª´ audio
        for res in audio_candidates:
            if res.id not in all_details:
                all_details[res.id] = []
            all_details[res.id].append(
                MatchDetail(
                    type="audio",
                    start_time=res.start,
                    end_time=res.end,
                    text_match=res.match,
                    score=res.score,
                )
            )

        final_results = []
        for media_id, data in sorted_media[:top_k]:
            # L·∫•y thumbnail cho k·∫øt qu·∫£
            image_base64 = await self._get_thumbnail_for_media(media_id)

            item_details = sorted(
                all_details.get(media_id, []),
                key=lambda d: d.timestamp or d.start_time or 0,
            )

            final_results.append(
                UnifiedResult(
                    id=media_id,
                    score=data["score"],
                    reason=sorted(list(data["reason"])),
                    image=image_base64,
                    details=item_details,
                )
            )
        return final_results

    def _fuse_results_rrf(
        self,
        visual_results: List[VisualResult],
        audio_results: List[AudioResult],
        k: int = 60,
    ) -> Dict:
        """H·ª£p nh·∫•t k·∫øt qu·∫£ b·∫±ng Reciprocal Rank Fusion (RRF)."""
        fused_scores = {}

        # X·ª≠ l√Ω visual results
        for rank, res in enumerate(visual_results):
            media_id = res.id
            if media_id not in fused_scores:
                fused_scores[media_id] = {"score": 0.0, "reason": set()}
            rrf_score = 1.0 / (k + rank + 1)
            fused_scores[media_id]["score"] += rrf_score
            fused_scores[media_id]["reason"].add("visual")

        # X·ª≠ l√Ω audio results
        for rank, res in enumerate(audio_results):
            media_id = res.id
            if media_id not in fused_scores:
                fused_scores[media_id] = {"score": 0.0, "reason": set()}
            # C√≥ th·ªÉ th√™m tr·ªçng s·ªë cho audio n·∫øu mu·ªën
            rrf_score = 1.0 / (k + rank + 1)
            fused_scores[media_id]["score"] += rrf_score
            fused_scores[media_id]["reason"].add("audio")

        return fused_scores

    async def _get_thumbnail_for_media(self, media_id: str) -> Optional[str]:
        """L·∫•y ·∫£nh thumbnail cho m·ªôt media_id m·ªôt c√°ch an to√†n v√† b·∫•t ƒë·ªìng b·ªô."""
        file_path = os.path.join(config.DATA_DIR, media_id)
        if not os.path.exists(file_path):
            return None

        # N·∫øu l√† file ·∫£nh, tr·∫£ v·ªÅ base64 c·ªßa n√≥ (h√†m n√†y ƒë√£ an to√†n)
        if any(media_id.lower().endswith(ext) for ext in config.IMAGE_EXTENSIONS):
            return self.vision_processor.image_to_base64(file_path)

        # N·∫øu l√† video, ch·∫°y logic blocking trong m·ªôt thread ri√™ng
        if any(media_id.lower().endswith(ext) for ext in config.VIDEO_EXTENSIONS):
            return await asyncio.to_thread(
                self._extract_video_thumbnail_sync, file_path
            )

        return None

    def _extract_video_thumbnail_sync(self, file_path: str) -> Optional[str]:
        """H√†m ƒë·ªìng b·ªô ƒë·ªÉ tr√≠ch xu·∫•t thumbnail. Ch·ªâ ƒë·ªÉ ch·∫°y trong a thread."""
        try:
            cap = cv2.VideoCapture(file_path)
            if not cap.isOpened():
                return None

            # L·∫•y frame ·ªü gi√¢y th·ª© 1
            cap.set(cv2.CAP_PROP_POS_MSEC, 1000)
            ret, frame = cap.read()
            cap.release()

            if ret:
                # Chuy·ªÉn ƒë·ªïi frame (numpy array) sang base64
                _, buffer = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
                img_base64 = base64.b64encode(buffer).decode("utf-8")
                return f"data:image/jpeg;base64,{img_base64}"
        except Exception as e:
            print(f"Error getting thumbnail for {os.path.basename(file_path)}: {e}")
        return None

    async def get_server_info(self) -> dict:
        """L·∫•y th√¥ng tin c∆° b·∫£n v·ªÅ server v√† d·ªØ li·ªáu."""
        try:
            es_ok = await self.es_client.ping()
            milvus_ok = (
                self.milvus_collection.has_partition("_default")
                if self.milvus_collection
                else False
            )
        except Exception:
            es_ok = False
            milvus_ok = False

        return {
            "message": "AI Multimodal Search API is running!",
            "version": "3.0.0-beta",
            "database_status": {
                "elasticsearch": "ok" if es_ok else "error",
                "milvus": "ok" if milvus_ok else "error",
            },
            "indexed_visuals": self.milvus_collection.num_entities if milvus_ok else 0,
            "model_info": self.vision_processor.get_model_info(),
        }
